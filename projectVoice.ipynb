{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projectVoice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xof7cx2YmMp"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import mglearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "#Read the voice dataset\n",
        "mydata = pd.read_csv(\"voice/voice.csv\")\n",
        "#Preview voice dataset\n",
        "mydata.head()\n",
        "print(mydata.shape)\n",
        "#Plot the histograms\n",
        "male = mydata.loc[mydata['label']=='male']\n",
        "female = mydata.loc[mydata['label']=='female']\n",
        "fig, axes = plt.subplots(10, 2, figsize=(10,20))\n",
        "ax = axes.ravel()\n",
        "for i in range(20):\n",
        "    ax[i].hist(male.ix[:,i], bins=20, color=mglearn.cm3(0), alpha=.5)\n",
        "    ax[i].hist(female.ix[:, i], bins=20, color=mglearn.cm3(2), alpha=.5)\n",
        "    ax[i].set_title(list(male)[i])\n",
        "    ax[i].set_yticks(())\n",
        "    \n",
        "ax[0].set_xlabel(\"Feature magnitude\")\n",
        "ax[0].set_ylabel(\"Frequency\")\n",
        "ax[0].legend([\"male\", \"female\"], loc=\"best\")\n",
        "fig.tight_layout()\n",
        "#Prepare data for modeling\n",
        "mydata.loc[:,'label'][mydata['label']==\"male\"] = 0\n",
        "mydata.loc[:,'label'][mydata['label']==\"female\"] = 1\n",
        "mydata_train, mydata_test = train_test_split(mydata, random_state=0, test_size=.2)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(mydata_train.ix[:,0:20])\n",
        "X_train = scaler.transform(mydata_train.ix[:,0:20])\n",
        "X_test = scaler.transform(mydata_test.ix[:,0:20])\n",
        "y_train = list(mydata_train['label'].values)\n",
        "y_test = list(mydata_test['label'].values)\n",
        "#Train decision tree model\n",
        "tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
        "print(\"Decision Tree\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))\n",
        "#Train random forest model\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
        "print(\"Random Forests\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))\n",
        "#Train gradient boosting model\n",
        "gbrt = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
        "print(\"Gradient Boosting\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n",
        "#Train support vector machine model\n",
        "svm = SVC().fit(X_train, y_train)\n",
        "print(\"Support Vector Machine\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(svm.score(X_test, y_test)))\n",
        "#Train neural network model\n",
        "mlp = MLPClassifier(random_state=0).fit(X_train, y_train)\n",
        "print(\"Multilayer Perceptron\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, y_test)))\n",
        "#Plot the variable importance\n",
        "def plot_feature_importances_mydata(model):\n",
        "    n_features = X_train.shape[1]\n",
        "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
        "    plt.yticks(np.arange(n_features), list(mydata))\n",
        "    plt.xlabel(\"Variable importance\")\n",
        "    plt.ylabel(\"Independent Variable\")\n",
        "plot_feature_importances_mydata(tree)\n",
        "plot_feature_importances_mydata(forest)\n",
        "plot_feature_importances_mydata(gbrt)\n",
        "#Plot the heatmap on first layer weights for neural network\n",
        "plt.figure(figsize=(100, 20))\n",
        "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\n",
        "plt.yticks(range(20), list(mydata),fontsize = 50)\n",
        "plt.xlabel(\"Columns in weight matrix\", fontsize = 50)\n",
        "plt.ylabel(\"Input feature\", fontsize = 50)\n",
        "plt.colorbar().set_label('Importance',size=50)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqBHiWAi2cpY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUo8DC0Jfl14",
        "outputId": "2ca129b3-7adb-4a08-9b41-497a0af04772"
      },
      "source": [
        "#подключаем библиотеки\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "!pip install mglearn\n",
        "!pip install sklearn\n",
        "!pip install -U scikit-learn\n",
        "import mglearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mglearn\n",
            "  Downloading mglearn-0.1.9.tar.gz (540 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 37.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 41.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 112 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 225 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 245 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 358 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 378 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 430 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 450 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 471 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 491 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 512 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 540 kB 29.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mglearn) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.1.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from mglearn) (7.1.2)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.11.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from mglearn) (2.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mglearn) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mglearn) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mglearn) (1.4.1)\n",
            "Building wheels for collected packages: mglearn\n",
            "  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582637 sha256=898f4ce989ff2610d11cede18365a18aa880301f223c458f1b013fda2d5213c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/17/e1/1720d6dcd70187b6b6c3750cb3508798f2b1d57c9d3214b08b\n",
            "Successfully built mglearn\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.1.9\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-1.0.1 threadpoolctl-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF4as4DCqn7T"
      },
      "source": [
        "#функция превращает аудиозаписи в картинки\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pylab\n",
        "def generate_spectogram(voice):\n",
        "    print(voice)\n",
        "    #voice = f'female (1).flac'\n",
        "\n",
        "    y, sr = librosa.load(voice, mono=True, duration=5)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # trim silent edges\n",
        "\n",
        "    whale_song, _ = librosa.effects.trim(y)\n",
        "\n",
        "    librosa.display.waveplot(whale_song, sr=sr);\n",
        "\n",
        "    n_fft = 2048\n",
        "\n",
        "    D = np.abs(librosa.stft(whale_song[:n_fft], n_fft=n_fft, hop_length=n_fft + 1))\n",
        "\n",
        "    hop_length = 256\n",
        "\n",
        "    D = np.abs(librosa.stft(whale_song, n_fft=n_fft, hop_length=hop_length))\n",
        "\n",
        "    librosa.display.specshow(D, sr=sr, y_axis='linear');\n",
        "\n",
        "    DB = librosa.amplitude_to_db(D, ref=np.max)\n",
        "\n",
        "    librosa.display.specshow(DB, sr=sr, hop_length=hop_length, y_axis='log');\n",
        "\n",
        "    pylab.axis('off')\n",
        "\n",
        "    plt.gca().set_axis_off()\n",
        "\n",
        "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
        "\n",
        "    plt.margins(0, 0)\n",
        "\n",
        "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
        "\n",
        "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
        "\n",
        "    voice = voice.split('/')[-1]\n",
        "  \n",
        "    fig.savefig(f'/content/drive/MyDrive/ПРоект АнДан/Спектограммы/val/male/{voice}.png') \n",
        "\n",
        "    plt.clf()\n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "kIP5XXzX2hFm",
        "outputId": "ca7e6a39-fde1-419a-8606-3ab737646edb"
      },
      "source": [
        "generate_spectogram(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-aa500a48fed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_spectogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWeFQcJEOHJJ"
      },
      "source": [
        "#превращение 37 женских аудиозаписей в картинку\n",
        "for i in range(393,466,1):\n",
        "  generate_spectogram('/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/Female voice/female (' + str(i) + ').flac') #это voice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WOS62046ffWa",
        "outputId": "9cf11a8b-63e5-4ec9-9bbb-08016375c1f8"
      },
      "source": [
        "import re\n",
        "x = '/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/Female voice/female (1).flac'\n",
        "y = 'Bye, World!'\n",
        "xx = x.split('/')\n",
        "xx[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'female (1).flac'"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "bkvLcKkgt40u",
        "outputId": "4169e5e8-eb45-42c4-dbe5-5cea12be6631"
      },
      "source": [
        "#превращение 37 мужских аудиозаписей в картинку\n",
        "for i in range(465,466,1):\n",
        "  generate_spectogram('/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/Male voice/male (' + str(i)+ ').flac') #/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/Male voice/male (142).flac"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/Male voice/male (465).flac\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y1MMePbX8G-"
      },
      "source": [
        "#подключаем библиотеки для обработки изображений\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGKE9Ig3Y-cK"
      },
      "source": [
        "# Каталог с данными для обучения\n",
        "train_dir = '/content/drive/MyDrive/ПРоект АнДан/Спектограммы/train'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = '/content/drive/MyDrive/ПРоект АнДан/Спектограммы/val'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = '/content/drive/MyDrive/ПРоект АнДан/Спектограммы/test'\n",
        "# Размеры изображения\n",
        "img_width, img_height = 432, 288\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "# backend Tensorflow, channels_last\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Количество эпох\n",
        "epochs = 30\n",
        "# Размер мини-выборки\n",
        "batch_size = 16\n",
        "# Количество изображений для обучения\n",
        "nb_train_samples = 574\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 174\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 182"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cpB6dFcwtqk"
      },
      "source": [
        "#создаем нейронную сеть для картинок\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "#компилируем нейронную сеть\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyq66yEOwvwm",
        "outputId": "17af6d50-4a5a-49b0-eee0-68d36ec60ce9"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255) #Генератор делит значения всех пикселов изображения на 255.\n",
        "\n",
        "#Генератор данных для обучения на основе изображений из каталога\n",
        "#для train данных\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 573 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NquVdTnx0iJ",
        "outputId": "93ad30a8-cf61-48b7-a3b7-fab86ba2af9a"
      },
      "source": [
        "#для val данных\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 175 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8kc_6Nux0r1",
        "outputId": "a5284f35-3aff-43ba-8141-44a9d745b2d4"
      },
      "source": [
        "#для test данных\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 182 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb4HtyQ_bwOI",
        "outputId": "885a8d4c-915c-4b12-a19e-6fd8a23bc93e"
      },
      "source": [
        "%%time\n",
        "#обучение модели с помощью генератора\n",
        "model.fit_generator(\n",
        "    train_generator, #train_generator - генератор данных для обучения\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator, #validation_data - генератор данных для проверки\n",
        "    validation_steps=nb_validation_samples // batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1963: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "35/35 [==============================] - 180s 5s/step - loss: 0.7671 - accuracy: 0.5440 - val_loss: 0.5864 - val_accuracy: 0.8062\n",
            "Epoch 2/30\n",
            "35/35 [==============================] - 82s 2s/step - loss: 0.4219 - accuracy: 0.8133 - val_loss: 0.3448 - val_accuracy: 0.8313\n",
            "Epoch 3/30\n",
            "35/35 [==============================] - 82s 2s/step - loss: 0.1970 - accuracy: 0.9250 - val_loss: 0.3236 - val_accuracy: 0.8750\n",
            "Epoch 4/30\n",
            "35/35 [==============================] - 82s 2s/step - loss: 0.1462 - accuracy: 0.9461 - val_loss: 0.3307 - val_accuracy: 0.8813\n",
            "Epoch 5/30\n",
            "35/35 [==============================] - 82s 2s/step - loss: 0.1081 - accuracy: 0.9623 - val_loss: 0.3631 - val_accuracy: 0.8313\n",
            "Epoch 6/30\n",
            "31/35 [=========================>....] - ETA: 8s - loss: 0.1212 - accuracy: 0.9513 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "-dcerlQC6WWf",
        "outputId": "99951654-1b84-410b-e8e9-f07b55c40e52"
      },
      "source": [
        "k = '/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/АнДанТнст.m4a'\n",
        "new = generate_spectogram(k)\n",
        "model.predict(new)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/АнДанТнст.m4a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-36049656231d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/АнДанТнст.m4a'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_spectogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1720\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1146\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1150\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 992\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    993\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "2gabvNJky5Uh",
        "outputId": "98f19b0f-2ef7-400c-afc6-0a7c4a9777d8"
      },
      "source": [
        "#оценка аккуратности данных\n",
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-90762b3d645d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#оценка аккуратности данных\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_test_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Аккуратность на тестовых данных: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "pTmIx8NQKcne",
        "outputId": "cdacea19-eb48-44ca-ca4d-7c9a0ec1d820"
      },
      "source": [
        "pip install pyTelegramBotAPI\n",
        "import telebot\n",
        "from telebot import types\n",
        "#1840603958:AAHYjyuGKnfIFlEmclpx-9agQywzI3Cpj-I\n",
        "name =''\n",
        "surname = ''\n",
        "age = 0\n",
        "bot = telebot.TeleBot(\"1840603958:AAHYjyuGKnfIFlEmclpx-9agQywzI3Cpj-I\", parse_mode=None)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-02868cdd10b9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install pyTelegramBotAPI\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhCmmPr7f_mX",
        "outputId": "6e3a2323-2660-46cb-be8d-1eff4010cbf7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "ltk4bbQeodd9",
        "outputId": "5d1a5355-657c-41bb-d310-4e3ad8317ff1"
      },
      "source": [
        "'/content/drive/MyDrive/ПРоект АнДан/Спектограммы/Female png' = generate_spectogram('/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/Female voice/female (37).flac')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-a6a5ffe24bdb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    '/content/drive/MyDrive/ПРоект АнДан/Спектограммы/Female png' = generate_spectogram('/content/drive/MyDrive/ПРоект АнДан/Аудиозаписи/Female voice/female (37).flac')\u001b[0m\n\u001b[0m                                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnQen5AQsxlq"
      },
      "source": [
        "plt = 'male (8).flac.png'\n",
        "\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "Qzr0D2wqr6Tb",
        "outputId": "60424e29-7785-493e-8a1f-732e0747e381"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('female (1).flac.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_9d4d759a-1daa-4f02-aecd-9314565b0371\", \"female (1).flac.png\", 187973)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LELV0_Mwf2M2"
      },
      "source": [
        "#Read the voice dataset\n",
        "mydata = pd.read_csv(\"voice.csv\")\n",
        "\n",
        "#Preview voice dataset\n",
        "mydata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EhHq2HQDfL5"
      },
      "source": [
        "X = mydata.drop(columns=['label']) #dataset without gender identifier\n",
        "y = mydata['label'] #gender identifier column\n",
        "X.head() #Preview \"x\" dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wZaJOU83ZdI",
        "outputId": "f1de67a7-429c-437c-e6cd-19b11419d6fe"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder #importing LabelEncoder \n",
        "labelencoder = LabelEncoder()\n",
        "Y = labelencoder.fit_transform(y) #transforming string data into number set\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duvk-c3J-WSy",
        "outputId": "dfc3fe3a-28bf-45e0-9031-9011db994eaa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.33, random_state = 42)\n",
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3168, 20)\n",
            "(2122, 20)\n",
            "(1046, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jhOPS3gBnkk",
        "outputId": "4904dff2-ecb8-4a57-8b68-93282123000c"
      },
      "source": [
        "#Train decision tree model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train) #learning\n",
        "y_prediction = clf.predict(X_test) #model is trying to predict by itself\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "accuracy_score(y_test, y_prediction)  #comparing prediction and the giving answers\n",
        "confusion_matrix(y_test, y_prediction) #right prediction for each group"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[479,  20],\n",
              "       [ 21, 526]])"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxPTOApcDPGf",
        "outputId": "a93978ae-51a7-4481-a654-8b1eb3b0690f"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "male      547\n",
              "female    499\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DWtStye5Ve8"
      },
      "source": [
        "    #Train random forest model\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
        "print(\"Random Forests\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu_3HaTJ5eoJ"
      },
      "source": [
        "#Train gradient boosting model\n",
        "gbrt = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
        "print(\"Gradient Boosting\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LooU5pD27gxs"
      },
      "source": [
        "#Train support vector machine model\n",
        "svm = SVC().fit(X_train, y_train)\n",
        "print(\"Support Vector Machine\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(svm.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv4Cg6Sg7g7k"
      },
      "source": [
        "#Train neural network model\n",
        "mlp = MLPClassifier(random_state=0).fit(X_train, y_train)\n",
        "print(\"Multilayer Perceptron\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIP2IeJw7hEG"
      },
      "source": [
        "#Plot the variable importance\n",
        "def plot_feature_importances_mydata(model):\n",
        "    n_features = X_train.shape[1]\n",
        "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
        "    plt.yticks(np.arange(n_features), list(mydata))\n",
        "    plt.xlabel(\"Variable importance\")\n",
        "    plt.ylabel(\"Independent Variable\")\n",
        "plot_feature_importances_mydata(tree)\n",
        "plot_feature_importances_mydata(forest)\n",
        "plot_feature_importances_mydata(gbrt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi04Z03H7v-e"
      },
      "source": [
        "#Plot the heatmap on first layer weights for neural network\n",
        "plt.figure(figsize=(100, 20))\n",
        "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\n",
        "plt.yticks(range(20), list(mydata),fontsize = 50)\n",
        "plt.xlabel(\"Columns in weight matrix\", fontsize = 50)\n",
        "plt.ylabel(\"Input feature\", fontsize = 50)\n",
        "plt.colorbar().set_label('Importance',size=50)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOrtwdQHc5hj"
      },
      "source": [
        "# Новый раздел"
      ]
    }
  ]
}